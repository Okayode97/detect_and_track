{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Notebook to experiment with model optimizing model for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1+cu121\n"
     ]
    }
   ],
   "source": [
    "# import dependencies\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from time import time\n",
    "from torchvision.models import detection\n",
    "import torch.utils.benchmark as benchmark\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SSD(\n",
       "  (backbone): SSDLiteFeatureExtractorMobileNet(\n",
       "    (features): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
       "              (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "              (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2dNormActivation(\n",
       "              (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): InvertedResidual(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
       "              (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2dNormActivation(\n",
       "              (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (4): InvertedResidual(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
       "              (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): ReLU()\n",
       "              (scale_activation): Hardsigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (5): InvertedResidual(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "              (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): ReLU()\n",
       "              (scale_activation): Hardsigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (6): InvertedResidual(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "              (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): ReLU(inplace=True)\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): ReLU()\n",
       "              (scale_activation): Hardsigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (7): InvertedResidual(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): Hardswish()\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "              (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): Hardswish()\n",
       "            )\n",
       "            (2): Conv2dNormActivation(\n",
       "              (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (8): InvertedResidual(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): Hardswish()\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
       "              (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): Hardswish()\n",
       "            )\n",
       "            (2): Conv2dNormActivation(\n",
       "              (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (9): InvertedResidual(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): Hardswish()\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
       "              (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): Hardswish()\n",
       "            )\n",
       "            (2): Conv2dNormActivation(\n",
       "              (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (10): InvertedResidual(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): Hardswish()\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
       "              (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): Hardswish()\n",
       "            )\n",
       "            (2): Conv2dNormActivation(\n",
       "              (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (11): InvertedResidual(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): Hardswish()\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "              (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): Hardswish()\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): ReLU()\n",
       "              (scale_activation): Hardsigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (12): InvertedResidual(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): Hardswish()\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "              (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): Hardswish()\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): ReLU()\n",
       "              (scale_activation): Hardsigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (13): Conv2dNormActivation(\n",
       "          (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Sequential(\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): InvertedResidual(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): Hardswish()\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "              (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): Hardswish()\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): ReLU()\n",
       "              (scale_activation): Hardsigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): InvertedResidual(\n",
       "          (block): Sequential(\n",
       "            (0): Conv2dNormActivation(\n",
       "              (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): Hardswish()\n",
       "            )\n",
       "            (1): Conv2dNormActivation(\n",
       "              (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "              (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (2): Hardswish()\n",
       "            )\n",
       "            (2): SqueezeExcitation(\n",
       "              (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "              (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (activation): ReLU()\n",
       "              (scale_activation): Hardsigmoid()\n",
       "            )\n",
       "            (3): Conv2dNormActivation(\n",
       "              (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (2): Hardswish()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (extra): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(480, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
       "          (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
       "          (1): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
       "          (1): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "          (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (anchor_generator): DefaultBoxGenerator(aspect_ratios=[[2, 3], [2, 3], [2, 3], [2, 3], [2, 3], [2, 3]], clip=True, scales=[0.2, 0.35, 0.5, 0.65, 0.8, 0.95, 1.0], steps=None)\n",
       "  (head): SSDLiteHead(\n",
       "    (classification_head): SSDLiteClassificationHead(\n",
       "      (module_list): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2d(672, 546, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2d(480, 546, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "            (1): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2d(512, 546, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3-4): 2 x Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2d(256, 546, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (5): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2d(128, 546, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (regression_head): SSDLiteRegressionHead(\n",
       "      (module_list): ModuleList(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2d(672, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2d(480, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
       "            (1): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3-4): 2 x Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2d(256, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (5): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "            (2): ReLU6(inplace=True)\n",
       "          )\n",
       "          (1): Conv2d(128, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
       "      Resize(min_size=(320,), max_size=320, mode='bilinear')\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load baseline model for optimization and benchmarking...\n",
    "baseline_model = detection.ssdlite320_mobilenet_v3_large(weights=detection.SSDLite320_MobileNet_V3_Large_Weights.DEFAULT)\n",
    "baseline_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking on 2 threads\n"
     ]
    }
   ],
   "source": [
    "# benchmark basic model.\n",
    "num_threads = torch.get_num_threads()\n",
    "print(f\"Benchmarking on {num_threads} threads\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarking Baseline Model\n",
    "- Attempt: Benchmark the baseline model and try using reducing image size used to benchmark model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x73c853ba4550>\n",
      "Baseline model\n",
      "setup:\n",
      "  import torch\n",
      "  from __main__ import baseline_model\n",
      "\n",
      "  x = torch.rand(1, 3, 640, 480)\n",
      "\n",
      "  630.29 ms\n",
      "  1 measurement, 100 runs , 2 threads\n"
     ]
    }
   ],
   "source": [
    "# benchmark model\n",
    "setup = '''\n",
    "import torch\n",
    "from __main__ import baseline_model\n",
    "\n",
    "x = torch.rand(1, 3, 640, 480)\n",
    "'''\n",
    "\n",
    "baseline_benchmark = benchmark.Timer(\n",
    "    stmt = \"baseline_model(x)\",\n",
    "    setup= setup,\n",
    "    num_threads=num_threads,\n",
    "    label=\"Baseline model\")\n",
    "\n",
    "print(baseline_benchmark.timeit(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x73c859fefc40>\n",
      "Baseline model: reduced resolution\n",
      "setup:\n",
      "  import torch\n",
      "  from __main__ import baseline_model\n",
      "\n",
      "  x = torch.rand(1, 3, 320, 240)\n",
      "\n",
      "  538.00 ms\n",
      "  1 measurement, 100 runs , 2 threads\n"
     ]
    }
   ],
   "source": [
    "reduced_resolution_setup = '''\n",
    "import torch\n",
    "from __main__ import baseline_model\n",
    "\n",
    "x = torch.rand(1, 3, 320, 240)\n",
    "'''\n",
    "\n",
    "baseline_benchmark_reduced_resolution =  benchmark.Timer(\n",
    "    stmt = \"baseline_model(x)\",\n",
    "    setup= reduced_resolution_setup,\n",
    "    num_threads=num_threads,\n",
    "    label=\"Baseline model\",\n",
    "    sub_label=\"reduced resolution\")\n",
    "\n",
    "print(baseline_benchmark_reduced_resolution.timeit(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch Scripting\n",
    "general points to note scripting and tracing applies optimization to the model to improves inference speed in production environment. Tracing the model effectively freezes the conditional logic of the model to match the data given during tracing. There are more subtle difference between the two approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply torch scripitng...\n",
    "scripted_model = torch.jit.script(baseline_model.eval())\n",
    "scripted_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# benchmark the performance of the model\n",
    "setup = '''\n",
    "import torch\n",
    "from __main__ import scripted_model\n",
    "\n",
    "x = torch.rand(3, 640, 480)\n",
    "'''\n",
    "scripted_model_benchmark = benchmark.Timer(\n",
    "    stmt = \"scripted_model([x])\", # interesting note that i've add to pass the \n",
    "    setup= setup,\n",
    "    num_threads=num_threads,\n",
    "    label=\"Scripted baseline model\")\n",
    "\n",
    "print(scripted_model_benchmark.timeit(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scripting the model results in some improvement in time taken to run inference, the resulting speedup are not consistent with multiple run. As a sidenote i've also tried reducing the resolution of the input image passed to the model to see if it improves inference time, it doesn't seem to result in any significant speed up. The results reported above where obtained after briefly going through notes on torchscripting there might be more details/approach to scripting and tracing that might improve inference time.\n",
    "\n",
    "i'll try other approaches\n",
    "- quantizations\n",
    "- experimenting with onnx runtime\n",
    "\n",
    "https://www.reddit.com/r/MachineLearning/comments/yg1mpz/d_how_to_get_the_fastest_pytorch_inference_and/\n",
    "\n",
    "As a side note or maybe a more concluding thought on scripting as an optimization approach.   \n",
    "Scripted model main advantage is that they can also run independently of a python environment, So they are designed to be flexible and portable, enabling deployment into a non-python environment. They are not necessarily an optimization technique to speed up inference, it's more focused on flexible and portable deployments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization\n",
    "(More of a summary of notes in model optimization.md)\n",
    "\n",
    "Quantization is an optimization technique that can be applied to a model to reduce it's size and increase it's inference speed (with the caveat that we have *about* the same accuracy as the original model). Quantization at a glance operates by converting high precision numbers into lower precision, the result is a reduction in model size and computational cost, with some negliable loss in accuracy. Three [approaches](https://pytorch.org/tutorials/recipes/quantization.html) to quantization are\n",
    "- Post training Dynamic Quantization (converts model weight to 8bit integers but does not convert activation untill it's used to compute further activation. At time of writing this method only supports nn.Linear and nn.LSTM modules to apply quantization to.)\n",
    "- Post training Static Quantization (Converts both weights and activation to 8 bit integers, there is no on-the-fly conversion of the model activation during inference)\n",
    "- Quantization aware training (from what i can gather this approach involves quantizing/dequantizing the inputs and activation of the model, the conversion is baked into the model architecture and used as part of model training..)\n",
    "\n",
    "\n",
    "for my application is it worth checking if there already exist a quantized version of the detection models?? There are quantized versions of the backbone but there are no quantized versions of the detection models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['qnnpack', 'none', 'onednn', 'x86', 'fbgemm']\n"
     ]
    }
   ],
   "source": [
    "print(torch.backends.quantized.supported_engines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kayode/Projects/detect_and_track/venv/lib/python3.10/site-packages/torch/ao/quantization/observer.py:1272: UserWarning: must run observer before calling calculate_qparams.                                    Returning default scale and zero point \n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Post training static quantization\n",
    "backend = \"qnnpack\"\n",
    "\n",
    "baseline_model = baseline_model.to(\"cpu\")\n",
    "\n",
    "baseline_model.qconfig = torch.quantization.get_default_qconfig(backend)\n",
    "torch.backends.quantized.engine = backend\n",
    "model_static_quantized = torch.quantization.prepare(baseline_model, inplace=False)\n",
    "model_static_quantized = torch.quantization.convert(model_static_quantized, inplace=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Could not run 'quantized::conv2d.new' with arguments from the 'CPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'quantized::conv2d.new' is only available for these backends: [Meta, QuantizedCPU, QuantizedCUDA, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMeta, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nMeta: registered at ../aten/src/ATen/core/MetaFallbackKernel.cpp:23 [backend fallback]\nQuantizedCPU: registered at ../aten/src/ATen/native/quantized/cpu/qconv.cpp:1928 [kernel]\nQuantizedCUDA: registered at ../aten/src/ATen/native/quantized/cudnn/Conv.cpp:391 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:154 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:497 [backend fallback]\nFunctionalize: registered at ../aten/src/ATen/FunctionalizeFallbackKernel.cpp:324 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at ../aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:86 [backend fallback]\nAutogradOther: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:53 [backend fallback]\nAutogradCPU: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:57 [backend fallback]\nAutogradCUDA: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:65 [backend fallback]\nAutogradXLA: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:69 [backend fallback]\nAutogradMPS: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:77 [backend fallback]\nAutogradXPU: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:61 [backend fallback]\nAutogradHPU: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:90 [backend fallback]\nAutogradLazy: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:73 [backend fallback]\nAutogradMeta: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:81 [backend fallback]\nTracer: registered at ../torch/csrc/autograd/TraceTypeManual.cpp:297 [backend fallback]\nAutocastCPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:378 [backend fallback]\nAutocastCUDA: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:244 [backend fallback]\nFuncTorchBatched: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:731 [backend fallback]\nBatchedNestedTensor: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:758 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at ../aten/src/ATen/functorch/VmapModeRegistrations.cpp:27 [backend fallback]\nBatched: registered at ../aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at ../aten/src/ATen/functorch/TensorWrapper.cpp:202 [backend fallback]\nPythonTLSSnapshot: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:162 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:493 [backend fallback]\nPreDispatch: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:166 [backend fallback]\nPythonDispatcher: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:158 [backend fallback]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m quant \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mao\u001b[38;5;241m.\u001b[39mquantization\u001b[38;5;241m.\u001b[39mQuantStub()\n\u001b[1;32m      5\u001b[0m x_quantized \u001b[38;5;241m=\u001b[39m quant(x)\n\u001b[0;32m----> 6\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_static_quantized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_quantized\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(prediction)\n",
      "File \u001b[0;32m~/Projects/detect_and_track/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/detect_and_track/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/detect_and_track/venv/lib/python3.10/site-packages/torchvision/models/detection/ssd.py:371\u001b[0m, in \u001b[0;36mSSD.forward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m    364\u001b[0m             torch\u001b[38;5;241m.\u001b[39m_assert(\n\u001b[1;32m    365\u001b[0m                 \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    366\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll bounding boxes should have positive height and width.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    367\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Found invalid box \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdegen_bb\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for target at index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    368\u001b[0m             )\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# get the features from the backbone\u001b[39;00m\n\u001b[0;32m--> 371\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(features, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    373\u001b[0m     features \u001b[38;5;241m=\u001b[39m OrderedDict([(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m, features)])\n",
      "File \u001b[0;32m~/Projects/detect_and_track/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/detect_and_track/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/detect_and_track/venv/lib/python3.10/site-packages/torchvision/models/detection/ssdlite.py:154\u001b[0m, in \u001b[0;36mSSDLiteFeatureExtractorMobileNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    152\u001b[0m output \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures:\n\u001b[0;32m--> 154\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m     output\u001b[38;5;241m.\u001b[39mappend(x)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextra:\n",
      "File \u001b[0;32m~/Projects/detect_and_track/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/detect_and_track/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/detect_and_track/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Projects/detect_and_track/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/detect_and_track/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/detect_and_track/venv/lib/python3.10/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Projects/detect_and_track/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/detect_and_track/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/detect_and_track/venv/lib/python3.10/site-packages/torch/ao/nn/quantized/modules/conv.py:468\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    465\u001b[0m     _reversed_padding_repeated_twice \u001b[38;5;241m=\u001b[39m _reverse_repeat_padding(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding)\n\u001b[1;32m    466\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, _reversed_padding_repeated_twice,\n\u001b[1;32m    467\u001b[0m                   mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode)\n\u001b[0;32m--> 468\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantized\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_packed_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_point\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/detect_and_track/venv/lib/python3.10/site-packages/torch/_ops.py:854\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self_, *args, **kwargs)\u001b[0m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(self_, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    847\u001b[0m     \u001b[38;5;66;03m# use `self_` to avoid naming collide with aten ops arguments that\u001b[39;00m\n\u001b[1;32m    848\u001b[0m     \u001b[38;5;66;03m# named \"self\". This way, all the aten ops can be called by kwargs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# We save the function ptr as the `op` attribute on\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# OpOverloadPacket to access it here.\u001b[39;00m\n\u001b[0;32m--> 854\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mself_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Could not run 'quantized::conv2d.new' with arguments from the 'CPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'quantized::conv2d.new' is only available for these backends: [Meta, QuantizedCPU, QuantizedCUDA, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradMPS, AutogradXPU, AutogradHPU, AutogradLazy, AutogradMeta, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, BatchedNestedTensor, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PreDispatch, PythonDispatcher].\n\nMeta: registered at ../aten/src/ATen/core/MetaFallbackKernel.cpp:23 [backend fallback]\nQuantizedCPU: registered at ../aten/src/ATen/native/quantized/cpu/qconv.cpp:1928 [kernel]\nQuantizedCUDA: registered at ../aten/src/ATen/native/quantized/cudnn/Conv.cpp:391 [kernel]\nBackendSelect: fallthrough registered at ../aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:154 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:497 [backend fallback]\nFunctionalize: registered at ../aten/src/ATen/FunctionalizeFallbackKernel.cpp:324 [backend fallback]\nNamed: registered at ../aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at ../aten/src/ATen/ConjugateFallback.cpp:17 [backend fallback]\nNegative: registered at ../aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at ../aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:86 [backend fallback]\nAutogradOther: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:53 [backend fallback]\nAutogradCPU: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:57 [backend fallback]\nAutogradCUDA: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:65 [backend fallback]\nAutogradXLA: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:69 [backend fallback]\nAutogradMPS: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:77 [backend fallback]\nAutogradXPU: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:61 [backend fallback]\nAutogradHPU: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:90 [backend fallback]\nAutogradLazy: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:73 [backend fallback]\nAutogradMeta: registered at ../aten/src/ATen/core/VariableFallbackKernel.cpp:81 [backend fallback]\nTracer: registered at ../torch/csrc/autograd/TraceTypeManual.cpp:297 [backend fallback]\nAutocastCPU: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:378 [backend fallback]\nAutocastCUDA: fallthrough registered at ../aten/src/ATen/autocast_mode.cpp:244 [backend fallback]\nFuncTorchBatched: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:731 [backend fallback]\nBatchedNestedTensor: registered at ../aten/src/ATen/functorch/LegacyBatchingRegistrations.cpp:758 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at ../aten/src/ATen/functorch/VmapModeRegistrations.cpp:27 [backend fallback]\nBatched: registered at ../aten/src/ATen/LegacyBatchingRegistrations.cpp:1075 [backend fallback]\nVmapMode: fallthrough registered at ../aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at ../aten/src/ATen/functorch/TensorWrapper.cpp:202 [backend fallback]\nPythonTLSSnapshot: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:162 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at ../aten/src/ATen/functorch/DynamicLayer.cpp:493 [backend fallback]\nPreDispatch: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:166 [backend fallback]\nPythonDispatcher: registered at ../aten/src/ATen/core/PythonFallbackKernel.cpp:158 [backend fallback]\n"
     ]
    }
   ],
   "source": [
    "# try running inference on quantized model\n",
    "x = torch.rand(1, 3, 640, 480)\n",
    "\n",
    "quant = torch.ao.quantization.QuantStub()\n",
    "x_quantized = quant(x)\n",
    "prediction = model_static_quantized(x_quantized)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "understanding *Could not run 'quantized::conv2d.new' with arguments from the 'CPU' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build).*\n",
    "looking at this [post](https://discuss.pytorch.org/t/error-in-running-quantised-model-runtimeerror-could-not-run-quantized-conv2d-new-with-arguments-from-the-cpu-backend/151718) it seems that you have to quanitize the input passed to the quantized model, and the approach is use `QuantStub` and `DeQuantStub` function to quantize and dequantize the input. Also it seems a different approach to quantizating the specific layers in the model was introduced (the different approach seems to be more related to quantization aware training), it might be worth trying with\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap model input and output, quantizing input and de-quantizing the output\n",
    "class QuantizedModel(torch.nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model_fp32 = model\n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = self.model_fp32(x)\n",
    "        x = self.dequant(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kayode/Projects/detect_and_track/venv/lib/python3.10/site-packages/torch/ao/quantization/observer.py:220: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# quantize model with inputs wrapped with quant & dequant function\n",
    "quantized_model = QuantizedModel(baseline_model)\n",
    "\n",
    "backend = \"fbgemm\"\n",
    "baseline_model.qconfig = torch.quantization.get_default_qconfig(backend)\n",
    "torch.backends.quantized.engine = backend\n",
    "model_static_quantized = torch.quantization.prepare(quantized_model, inplace=False)\n",
    "model_static_quantized = torch.quantization.convert(quantized_model, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'boxes': tensor([[  9.0042,  14.6606, 473.1248, 626.1837],\n",
      "        [ 14.1597,   8.8701, 467.1629, 631.9363],\n",
      "        [ 14.0687,   2.5829, 467.1468, 636.5439],\n",
      "        ...,\n",
      "        [249.1153, 359.3487, 266.7929, 380.8774],\n",
      "        [286.4323, 193.1816, 307.2702, 243.4322],\n",
      "        [266.7977, 256.2302, 287.4995, 299.5911]], grad_fn=<StackBackward0>), 'scores': tensor([0.0438, 0.0326, 0.0269, 0.0257, 0.0248, 0.0218, 0.0217, 0.0211, 0.0211,\n",
      "        0.0208, 0.0196, 0.0196, 0.0189, 0.0186, 0.0177, 0.0171, 0.0170, 0.0169,\n",
      "        0.0169, 0.0167, 0.0165, 0.0163, 0.0163, 0.0161, 0.0161, 0.0161, 0.0161,\n",
      "        0.0158, 0.0157, 0.0155, 0.0154, 0.0154, 0.0153, 0.0153, 0.0151, 0.0150,\n",
      "        0.0150, 0.0150, 0.0150, 0.0148, 0.0148, 0.0147, 0.0147, 0.0147, 0.0147,\n",
      "        0.0147, 0.0146, 0.0146, 0.0146, 0.0145, 0.0145, 0.0144, 0.0144, 0.0143,\n",
      "        0.0142, 0.0142, 0.0142, 0.0141, 0.0140, 0.0140, 0.0139, 0.0139, 0.0138,\n",
      "        0.0138, 0.0137, 0.0137, 0.0137, 0.0137, 0.0137, 0.0136, 0.0136, 0.0136,\n",
      "        0.0136, 0.0136, 0.0135, 0.0135, 0.0135, 0.0135, 0.0135, 0.0134, 0.0134,\n",
      "        0.0134, 0.0134, 0.0133, 0.0133, 0.0133, 0.0133, 0.0132, 0.0132, 0.0132,\n",
      "        0.0132, 0.0132, 0.0131, 0.0131, 0.0131, 0.0131, 0.0131, 0.0130, 0.0130,\n",
      "        0.0130, 0.0130, 0.0130, 0.0130, 0.0130, 0.0129, 0.0129, 0.0129, 0.0129,\n",
      "        0.0128, 0.0128, 0.0128, 0.0128, 0.0128, 0.0127, 0.0127, 0.0127, 0.0127,\n",
      "        0.0127, 0.0127, 0.0127, 0.0126, 0.0126, 0.0126, 0.0126, 0.0126, 0.0125,\n",
      "        0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0125, 0.0124, 0.0124,\n",
      "        0.0124, 0.0124, 0.0124, 0.0124, 0.0124, 0.0124, 0.0123, 0.0123, 0.0123,\n",
      "        0.0123, 0.0123, 0.0123, 0.0123, 0.0123, 0.0123, 0.0122, 0.0122, 0.0122,\n",
      "        0.0122, 0.0121, 0.0121, 0.0121, 0.0121, 0.0121, 0.0121, 0.0121, 0.0121,\n",
      "        0.0120, 0.0120, 0.0120, 0.0119, 0.0119, 0.0119, 0.0119, 0.0119, 0.0119,\n",
      "        0.0119, 0.0119, 0.0119, 0.0119, 0.0118, 0.0118, 0.0118, 0.0117, 0.0117,\n",
      "        0.0117, 0.0117, 0.0117, 0.0117, 0.0116, 0.0116, 0.0116, 0.0116, 0.0116,\n",
      "        0.0116, 0.0116, 0.0116, 0.0115, 0.0115, 0.0115, 0.0115, 0.0115, 0.0115,\n",
      "        0.0115, 0.0114, 0.0114, 0.0114, 0.0114, 0.0113, 0.0113, 0.0113, 0.0113,\n",
      "        0.0113, 0.0113, 0.0113, 0.0113, 0.0113, 0.0113, 0.0113, 0.0113, 0.0113,\n",
      "        0.0113, 0.0113, 0.0113, 0.0113, 0.0112, 0.0112, 0.0112, 0.0112, 0.0112,\n",
      "        0.0112, 0.0112, 0.0112, 0.0112, 0.0112, 0.0112, 0.0112, 0.0112, 0.0112,\n",
      "        0.0111, 0.0111, 0.0111, 0.0111, 0.0111, 0.0111, 0.0111, 0.0111, 0.0110,\n",
      "        0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110, 0.0110,\n",
      "        0.0110, 0.0109, 0.0109, 0.0109, 0.0109, 0.0109, 0.0109, 0.0109, 0.0109,\n",
      "        0.0108, 0.0108, 0.0108, 0.0108, 0.0108, 0.0108, 0.0108, 0.0108, 0.0108,\n",
      "        0.0108, 0.0108, 0.0108, 0.0108, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107,\n",
      "        0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107, 0.0107,\n",
      "        0.0106, 0.0106, 0.0106, 0.0106, 0.0106, 0.0106, 0.0106, 0.0106, 0.0106,\n",
      "        0.0106, 0.0106, 0.0106], grad_fn=<IndexBackward0>), 'labels': tensor([ 1, 63, 67,  1,  1, 16,  1, 16,  1, 16, 65, 16, 16, 16, 16, 16, 16, 67,\n",
      "        28, 16, 16, 16, 16, 16, 16, 16,  1, 16, 38, 16, 38, 16, 38, 16, 16, 16,\n",
      "        38,  1, 16, 38, 67, 16, 16, 16, 16, 16, 16, 16, 38,  1, 38, 38, 38, 38,\n",
      "        16, 16, 15, 38, 38, 38, 38, 38, 16, 16, 16, 16, 16,  1, 16,  1, 38, 16,\n",
      "         1, 38, 38,  1, 67, 16, 16, 16,  1,  1, 16, 67, 16, 16, 16, 16, 16, 38,\n",
      "        16, 16, 38, 16, 16, 16, 16,  1,  1, 16,  1, 16, 16, 67, 16, 38, 16, 62,\n",
      "        16, 16,  1, 38, 16, 16, 16, 16, 16, 16, 16, 38, 16,  1, 16, 67, 38, 16,\n",
      "         1, 16, 38, 16, 16,  1, 38, 38, 38, 16, 16, 16, 16, 16, 16, 16, 38, 16,\n",
      "        16, 38, 43, 16, 16, 16, 16, 16, 16, 16, 38, 16, 16, 16, 38, 16, 16, 16,\n",
      "        16, 16, 16,  1, 16, 16, 16, 38, 16,  1,  1, 16,  1, 38, 67, 16, 16, 38,\n",
      "        16, 38, 38, 16, 16, 16, 16,  1, 16, 16, 38, 38, 16, 16, 16, 16, 16, 16,\n",
      "        16, 16, 16, 38, 16,  1,  1, 16, 16, 62, 38, 16, 38, 38, 16, 38, 16, 16,\n",
      "        16, 16,  1, 67, 16, 16, 38, 38,  1, 16, 38, 16,  1, 16, 16, 16, 16, 16,\n",
      "        16,  1, 16, 16, 16, 16, 38, 16,  1, 38, 38, 16, 16, 16,  1, 16, 16, 16,\n",
      "        16, 16, 38,  1, 38, 16, 16, 16, 16,  1, 16,  1,  1,  1, 38, 38, 38,  1,\n",
      "         1, 16, 16, 16,  1, 16, 16, 16, 38, 16, 38, 16,  1, 38,  1, 16, 16, 16,\n",
      "         1, 16, 16, 38,  1, 16, 16, 38, 16, 16,  1, 16])}]\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(1, 3, 640, 480)\n",
    "\n",
    "# quant = torch.ao.quantization.QuantStub()\n",
    "# x_quantized = quant(x)\n",
    "prediction = model_static_quantized(x)\n",
    "print(prediction)\n",
    "\n",
    "# IT WORKS !!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried simply quantizing the inputs before running the model forward function, but runing that did not resolve the issue, but wrapping up the forward function for the quantized model class did the trick. Does that mean the quantization stubs need to be within the forward function of the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x73c85131e860>\n",
      "quantized model\n",
      "setup:\n",
      "  import torch\n",
      "  from __main__ import model_static_quantized\n",
      "\n",
      "  x = torch.rand(1, 3, 640, 480)\n",
      "\n",
      "  560.15 ms\n",
      "  1 measurement, 100 runs , 2 threads\n"
     ]
    }
   ],
   "source": [
    "# benchmark static quantized model\n",
    "setup = '''\n",
    "import torch\n",
    "from __main__ import model_static_quantized\n",
    "\n",
    "x = torch.rand(1, 3, 640, 480)\n",
    "'''\n",
    "quantized_model = benchmark.Timer(\n",
    "    stmt = \"model_static_quantized(x)\", # interesting note that i've add to pass the \n",
    "    setup= setup,\n",
    "    num_threads=num_threads,\n",
    "    label=\"quantized model\")\n",
    "\n",
    "print(quantized_model.timeit(100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resulting quantized model is not as fast as i would have thought. There are some improvements but the inference time is not consistent with multiple runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is there a difference in quantizing the model with different backend\n",
    "# available backend ['qnnpack', 'none', 'onednn', 'x86', 'fbgemm']\n",
    "\n",
    "def quantize_model_with_different_backend(model: torch.nn.Module, backend: str):\n",
    "\n",
    "    quantized_model = QuantizedModel(model.to(\"cpu\")) # not really quantized, but it's inputs and outputs have been wrapped with quantization stub\n",
    "\n",
    "    quantized_model.qconfig = torch.quantization.get_default_qconfig(backend)\n",
    "    torch.backends.quantized.engine = backend\n",
    "    model_static_quantized = torch.quantization.prepare(quantized_model, inplace=False)\n",
    "    model_static_quantized = torch.quantization.convert(quantized_model, inplace=False)\n",
    "    \n",
    "\n",
    "    return model_static_quantized\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quantizing with different backends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qnnpack model\n",
    "qnn_pack_backend_quantized_model = quantize_model_with_different_backend(baseline_model, \"qnnpack\")\n",
    "\n",
    "# benchmark static quantized model\n",
    "setup = '''\n",
    "import torch\n",
    "from __main__ import qnn_pack_backend_quantized_model\n",
    "\n",
    "x = torch.rand(1, 3, 640, 480)\n",
    "'''\n",
    "quantized_qnnpack_model = benchmark.Timer(\n",
    "    stmt = \"qnn_pack_backend_quantized_model(x)\", # interesting note that i've add to pass the \n",
    "    setup= setup,\n",
    "    num_threads=num_threads,\n",
    "    label=\"quantized qnnpack model\")\n",
    "\n",
    "print(quantized_qnnpack_model.timeit(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# onednn backend\n",
    "onednn_backend_quantized_model = quantize_model_with_different_backend(baseline_model, \"onednn\")\n",
    "\n",
    "# benchmark static quantized model\n",
    "setup = '''\n",
    "import torch\n",
    "from __main__ import onednn_backend_quantized_model\n",
    "\n",
    "x = torch.rand(1, 3, 640, 480)\n",
    "'''\n",
    "quantized_onednn_model = benchmark.Timer(\n",
    "    stmt = \"onednn_backend_quantized_model(x)\", # interesting note that i've add to pass the \n",
    "    setup= setup,\n",
    "    num_threads=num_threads,\n",
    "    label=\"quantized onednn model\")\n",
    "\n",
    "print(quantized_onednn_model.timeit(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x86 backend\n",
    "x86_backend_quantized_model = quantize_model_with_different_backend(baseline_model, \"x86\")\n",
    "\n",
    "# benchmark static quantized model\n",
    "setup = '''\n",
    "import torch\n",
    "from __main__ import x86_backend_quantized_model\n",
    "\n",
    "x = torch.rand(1, 3, 640, 480)\n",
    "'''\n",
    "quantized_x86_model = benchmark.Timer(\n",
    "    stmt = \"x86_backend_quantized_model(x)\", # interesting note that i've add to pass the \n",
    "    setup= setup,\n",
    "    num_threads=num_threads,\n",
    "    label=\"quantized x86 model\")\n",
    "\n",
    "print(quantized_x86_model.timeit(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try fusing model layers\n",
    "\n",
    "**Quantization backend Significance**   \n",
    "significance of different backend, which backend to use?   \n",
    "The different backends specfiy how quantized operations are implemented and optimized for specific hardware platform.   \n",
    "- `fbgem` backend, is `optimized for x86 platforms such as intels CPU`. It uses efficient algorithms and instructions specific to x86 hardware to maximize performance. It's optimized for x86 server CPU and is widely used in data center environment where intel or AMD x86 processors are predominant.\n",
    "\n",
    "- `qnnpack` is `optimized for mobile devices` such as ARM CPUs and is designed to offer efficient performance on smartphones and tablets, making it suitable for mobile applications. qnnpack supports 8-bit integer quantization and provides optimizations for mobile inference.\n",
    "\n",
    "- `onednn` is an `intel-developed library that provides optimization for both CPU and GPU`. It's used for server-side applications where intel hardware is predominant. It can be useful for both quantized and floating point compuations. Also worth noting that `onednn` is `focused on x86 intel platforms`, the key difference between it and `fbgem` is that it's `more versatile in that it provides optimization for both CPU and GPU`\n",
    "\n",
    "Given that i've switched from running the model locally on the raspberry pi to hosting it on a fastapi server on an old linux server, i can't use qnnpack backend so that leaves `x86`, `onednn`, `fbgem`, also looking at the benchmarking results with the model quantized with qnnpack, had the longest inference time. With fbgem and x86 giving the *best reduction in inference time* \n",
    "\n",
    "note.   \n",
    "- checking linux laptop: running `uname -m` gave results x86-64, querying on results indicated that laptop is running a 64-bit version of the x86 architecture, which is also known as \"AMD64\" or \"Intel 64.\" \n",
    "\n",
    "\n",
    "One last try, with **fusing model layers**\n",
    "**Try fusing model layers**\n",
    "Notes from [quantization in practice](https://pytorch.org/blog/quantization-in-practice/#backend-engine)\n",
    "- Post training static quantization:\n",
    "    - quantizes the model weightts and activation, as opposed to applying on-the-fly quantization for the activations. The activation would stay in a quantized precision between operations during inference.\n",
    "    - Additional methods to apply into post training static quantization workflow. Fuse modules, get calibration data and calibrate the model before applying quantization.\n",
    "\n",
    "*\"Module fusion combines multiple sequential modules into one. Fusing modules mean the compiler needs to only run one kernel instead of many; this speeds things up and improve accuracy by reducing quantization error\"* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backbone\n",
      "-------------\n",
      "anchor_generator\n",
      "-------------\n",
      "head\n",
      "-------------\n",
      "transform\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "from torch.ao.quantization import fuse_modules\n",
    "import copy\n",
    "\n",
    "\n",
    "baseline_model_copy = copy.deepcopy(baseline_model)\n",
    "for name, module in baseline_model_copy.named_children():\n",
    "    print(name)\n",
    "    print(\"-------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backbone SSDLiteFeatureExtractorMobileNet(\n",
      "  (features): Sequential(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (2): Hardswish()\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "            (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "            (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2dNormActivation(\n",
      "            (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "            (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): Conv2dNormActivation(\n",
      "            (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (4): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "            (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (5): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "            (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (6): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "            (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (7): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "            (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): Conv2dNormActivation(\n",
      "            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (8): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
      "            (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): Conv2dNormActivation(\n",
      "            (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (9): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "            (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): Conv2dNormActivation(\n",
      "            (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (10): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "            (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): Conv2dNormActivation(\n",
      "            (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (11): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "            (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (12): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "            (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (13): Conv2dNormActivation(\n",
      "        (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (2): Hardswish()\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Sequential(\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
      "          (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (2): Hardswish()\n",
      "        )\n",
      "        (2): SqueezeExcitation(\n",
      "          (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "          (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (activation): ReLU()\n",
      "          (scale_activation): Hardsigmoid()\n",
      "        )\n",
      "        (3): Conv2dNormActivation(\n",
      "          (0): Conv2d(672, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "            (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (2): InvertedResidual(\n",
      "        (block): Sequential(\n",
      "          (0): Conv2dNormActivation(\n",
      "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (1): Conv2dNormActivation(\n",
      "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "            (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "            (2): Hardswish()\n",
      "          )\n",
      "          (2): SqueezeExcitation(\n",
      "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
      "            (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (activation): ReLU()\n",
      "            (scale_activation): Hardsigmoid()\n",
      "          )\n",
      "          (3): Conv2dNormActivation(\n",
      "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (3): Conv2dNormActivation(\n",
      "        (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (2): Hardswish()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (extra): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(480, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
      "        (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2dNormActivation(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
      "        (1): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2dNormActivation(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
      "        (1): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2dNormActivation(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "        (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2dNormActivation(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "-------------\n",
      "anchor_generator DefaultBoxGenerator(aspect_ratios=[[2, 3], [2, 3], [2, 3], [2, 3], [2, 3], [2, 3]], clip=True, scales=[0.2, 0.35, 0.5, 0.65, 0.8, 0.95, 1.0], steps=None)\n",
      "-------------\n",
      "head SSDLiteHead(\n",
      "  (classification_head): SSDLiteClassificationHead(\n",
      "    (module_list): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "          (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2d(672, 546, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "          (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2d(480, 546, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
      "          (1): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2d(512, 546, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (3-4): 2 x Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "          (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2d(256, 546, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "          (1): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2d(128, 546, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (regression_head): SSDLiteRegressionHead(\n",
      "    (module_list): ModuleList(\n",
      "      (0): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "          (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2d(672, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "          (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2d(480, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
      "          (1): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (3-4): 2 x Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "          (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2d(256, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "          (1): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (2): ReLU6(inplace=True)\n",
      "        )\n",
      "        (1): Conv2d(128, 24, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "-------------\n",
      "transform GeneralizedRCNNTransform(\n",
      "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
      "    Resize(min_size=(320,), max_size=320, mode='bilinear')\n",
      ")\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "for name, module in baseline_model_copy.named_children():\n",
    "    print(name, module)\n",
    "    print(\"-------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
      "  (1): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
      "  (1): BatchNorm2d(120, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
      "  (1): BatchNorm2d(240, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
      "  (1): BatchNorm2d(200, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
      "  (1): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(112, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): Hardswish()\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU6(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
      "  (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU6(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU6(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU6(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
      "  (1): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU6(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU6(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU6(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
      "  (1): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU6(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU6(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU6(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
      "  (1): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU6(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU6(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU6(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU6(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU6(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU6(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
      "  (1): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU6(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
      "  (1): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU6(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "  (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU6(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "  (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU6(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "  (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU6(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "  (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU6(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "  (1): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU6(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "  (1): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU6(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU6(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
      "  (1): BatchNorm2d(672, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU6(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU6(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
      "  (1): BatchNorm2d(480, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU6(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
      "  (1): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU6(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
      "  (1): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU6(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "  (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU6(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "  (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU6(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "  (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU6(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "  (1): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU6(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "  (1): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU6(inplace=True)\n",
      ")\n",
      "Conv2dNormActivation(\n",
      "  (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
      "  (1): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "  (2): ReLU6(inplace=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# iterate through the backbone and fuse first two elements in conv2d norm activation block\n",
    "def find_all_conv2d_norm_activation_blocks_and_fuse_them(model):\n",
    "\n",
    "    def recurse_submodules(modules):\n",
    "        for name, sub_module in modules.named_children():\n",
    "            if type(sub_module) == torch.nn.modules.container.Sequential:\n",
    "               for layer in sub_module:\n",
    "                   if type(layer).__name__ == 'Conv2dNormActivation':\n",
    "                        # if type(layer[1]) == torch.nn.modules.batchnorm.BatchNorm2d:\n",
    "                        #     fuse_modules(layer, [\"0\", \"1\"], inplace=True)\n",
    "                        print(layer)\n",
    "                   else:\n",
    "                        recurse_submodules(sub_module)\n",
    "            else:\n",
    "                if type(sub_module).__name__ == 'Conv2dNormActivation':\n",
    "                    # if type(sub_module[1]) == torch.nn.modules.batchnorm.BatchNorm2d:\n",
    "                    #     fuse_modules(sub_module, [\"0\", \"1\"], inplace=True)\n",
    "                    print(sub_module)\n",
    "                else:\n",
    "                    recurse_submodules(sub_module)\n",
    "\n",
    "    recurse_submodules(model)\n",
    "\n",
    "find_all_conv2d_norm_activation_blocks_and_fuse_them(baseline_model_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7252f0202140>\n",
      "quantized fbgemm model\n",
      "setup:\n",
      "  import torch\n",
      "  from __main__ import fbgemm_backend_quantized_model\n",
      "\n",
      "  x = torch.rand(1, 3, 640, 480)\n",
      "\n",
      "  520.04 ms\n",
      "  1 measurement, 100 runs , 2 threads\n"
     ]
    }
   ],
   "source": [
    "#  model\n",
    "fbgem_model_copy = copy.deepcopy(baseline_model_copy)\n",
    "fbgemm_backend_quantized_model = quantize_model_with_different_backend(fbgem_model_copy, \"fbgemm\")\n",
    "\n",
    "# benchmark static quantized model\n",
    "setup = '''\n",
    "import torch\n",
    "from __main__ import fbgemm_backend_quantized_model\n",
    "\n",
    "x = torch.rand(1, 3, 640, 480)\n",
    "'''\n",
    "quantized_fbgemm_model_benchmark = benchmark.Timer(\n",
    "    stmt = \"fbgemm_backend_quantized_model(x)\", # interesting note that i've add to pass the \n",
    "    setup= setup,\n",
    "    num_threads=num_threads,\n",
    "    label=\"quantized fbgemm model\")\n",
    "\n",
    "print(quantized_fbgemm_model_benchmark.timeit(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.benchmark.utils.common.Measurement object at 0x7252f0203730>\n",
      "quantized x86 model\n",
      "setup:\n",
      "  import torch\n",
      "  from __main__ import x86_backend_quantized_model\n",
      "\n",
      "  x = torch.rand(1, 3, 640, 480)\n",
      "\n",
      "  508.12 ms\n",
      "  1 measurement, 100 runs , 2 threads\n"
     ]
    }
   ],
   "source": [
    "x86_model_copy = copy.deepcopy(baseline_model_copy)\n",
    "x86_backend_quantized_model = quantize_model_with_different_backend(x86_model_copy, \"x86\")\n",
    "\n",
    "# benchmark static quantized model\n",
    "setup = '''\n",
    "import torch\n",
    "from __main__ import x86_backend_quantized_model\n",
    "\n",
    "x = torch.rand(1, 3, 640, 480)\n",
    "'''\n",
    "quantized_x86_model_benchmark = benchmark.Timer(\n",
    "    stmt = \"x86_backend_quantized_model(x)\", # interesting note that i've add to pass the \n",
    "    setup= setup,\n",
    "    num_threads=num_threads,\n",
    "    label=\"quantized x86 model\")\n",
    "\n",
    "print(quantized_x86_model_benchmark.timeit(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
